{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract W and Black Holes from Qwen 3 4B Instruct 2507\n",
    "\n",
    "**Purpose:** Load the model, extract the unembedding matrix W, identify black holes (tokens with non-unique embeddings), and save everything as reusable artifacts.\n",
    "\n",
    "**Outputs:** `../tensors/qwen3_4b_instruct_2507.safetensors` containing:\n",
    "- `W` — The unembedding matrix [V, D] in bfloat16\n",
    "- `black_hole_mask` — Boolean mask, True for tokens in any black hole [V]\n",
    "- `black_hole_id` — uint8 assignment: 0 = not black hole, 1 = largest hole (814 tokens), 2 = second largest, etc. [V]\n",
    "- `black_hole_centroids` — The actual embedding vector for each black hole [num_holes, D] in bfloat16\n",
    "\n",
    "**Runtime:** ~30 seconds (model already cached)\n",
    "\n",
    "---\n",
    "\n",
    "*Jeffery Harrell & Alpha, December 1, 2025*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from safetensors.torch import save_file\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "We load in bfloat16 to preserve the exact quantization from training. The model is ~8GB; we only need the unembedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e0ca344489c40399420d30fd5a986bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: Qwen/Qwen3-4B-Instruct-2507\n",
      "Vocab size: 151,936\n",
      "Hidden dim: 2,560\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\",  # Don't need GPU for extraction\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {MODEL_ID}\")\n",
    "print(f\"Vocab size: {model.config.vocab_size:,}\")\n",
    "print(f\"Hidden dim: {model.config.hidden_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract W\n",
    "\n",
    "The unembedding matrix is `lm_head.weight` in Qwen's architecture. Shape: [vocab_size, hidden_dim]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape: torch.Size([151936, 2560])\n",
      "W dtype: torch.bfloat16\n",
      "W memory: 777.9 MB\n"
     ]
    }
   ],
   "source": [
    "W = model.lm_head.weight.detach().clone()\n",
    "\n",
    "print(f\"W shape: {W.shape}\")\n",
    "print(f\"W dtype: {W.dtype}\")\n",
    "print(f\"W memory: {W.numel() * 2 / 1e6:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Black Holes\n",
    "\n",
    "A \"black hole\" is a set of tokens that share a bit-for-bit identical embedding vector. We find them using `torch.unique()` with `return_inverse=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 151,936\n",
      "Unique vectors: 149,849\n",
      "Duplicated tokens: 2,087\n"
     ]
    }
   ],
   "source": [
    "# Find unique vectors and which unique vector each token maps to\n",
    "unique_vectors, inverse_indices = torch.unique(W, dim=0, return_inverse=True)\n",
    "\n",
    "num_unique = unique_vectors.shape[0]\n",
    "num_total = W.shape[0]\n",
    "num_duplicated = num_total - num_unique\n",
    "\n",
    "print(f\"Total tokens: {num_total:,}\")\n",
    "print(f\"Unique vectors: {num_unique:,}\")\n",
    "print(f\"Duplicated tokens: {num_duplicated:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of black holes: 13\n",
      "\n",
      "Black hole populations (sorted):\n",
      "  814 tokens\n",
      "  704 tokens\n",
      "  306 tokens\n",
      "  228 tokens\n",
      "  11 tokens\n",
      "  10 tokens\n",
      "  6 tokens\n",
      "  5 tokens\n",
      "  4 tokens\n",
      "  4 tokens\n",
      "  3 tokens\n",
      "  3 tokens\n",
      "  2 tokens\n"
     ]
    }
   ],
   "source": [
    "# Count how many tokens map to each unique vector\n",
    "# A black hole is any unique vector with count > 1\n",
    "counts = Counter(inverse_indices.tolist())\n",
    "\n",
    "# Find which unique-vector indices are black holes (count > 1)\n",
    "black_hole_unique_ids = {uid: count for uid, count in counts.items() if count > 1}\n",
    "\n",
    "print(f\"Number of black holes: {len(black_hole_unique_ids)}\")\n",
    "print(f\"\\nBlack hole populations (sorted):\")\n",
    "for uid, count in sorted(black_hole_unique_ids.items(), key=lambda x: -x[1]):\n",
    "    print(f\"  {count:,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Masks and ID Vectors\n",
    "\n",
    "- `black_hole_mask[i]` = True if token i is in any black hole\n",
    "- `black_hole_id[i]` = 0 if not in a black hole, else 1 for largest hole, 2 for second largest, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens in black holes: 2,100\n",
      "Max black hole ID: 13\n"
     ]
    }
   ],
   "source": [
    "# Sort black holes by population (descending)\n",
    "sorted_holes = sorted(black_hole_unique_ids.items(), key=lambda x: -x[1])\n",
    "\n",
    "# Map from unique-vector-id to black-hole-id (1-indexed)\n",
    "uid_to_bhid = {uid: bhid + 1 for bhid, (uid, _) in enumerate(sorted_holes)}\n",
    "\n",
    "# Build the tensors\n",
    "V = W.shape[0]\n",
    "black_hole_mask = torch.zeros(V, dtype=torch.bool)\n",
    "black_hole_id = torch.zeros(V, dtype=torch.uint8)\n",
    "\n",
    "for token_id, unique_id in enumerate(inverse_indices.tolist()):\n",
    "    if unique_id in uid_to_bhid:\n",
    "        black_hole_mask[token_id] = True\n",
    "        black_hole_id[token_id] = uid_to_bhid[unique_id]\n",
    "\n",
    "print(f\"Tokens in black holes: {black_hole_mask.sum().item():,}\")\n",
    "print(f\"Max black hole ID: {black_hole_id.max().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification — tokens per black hole:\n",
      "  Black hole 1: 814 tokens\n",
      "  Black hole 2: 704 tokens\n",
      "  Black hole 3: 306 tokens\n",
      "  Black hole 4: 228 tokens\n",
      "  Black hole 5: 11 tokens\n",
      "  Black hole 6: 10 tokens\n",
      "  Black hole 7: 6 tokens\n",
      "  Black hole 8: 5 tokens\n",
      "  Black hole 9: 4 tokens\n",
      "  Black hole 10: 4 tokens\n",
      "  Black hole 11: 3 tokens\n",
      "  Black hole 12: 3 tokens\n",
      "  Black hole 13: 2 tokens\n"
     ]
    }
   ],
   "source": [
    "# Verify: count tokens per black hole ID\n",
    "print(\"Verification — tokens per black hole:\")\n",
    "for bhid in range(1, black_hole_id.max().item() + 1):\n",
    "    count = (black_hole_id == bhid).sum().item()\n",
    "    print(f\"  Black hole {bhid}: {count:,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Black Hole Centroids\n",
    "\n",
    "Each black hole has a single embedding vector shared by all its members. We save these for easy access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black hole centroids shape: torch.Size([13, 2560])\n"
     ]
    }
   ],
   "source": [
    "# Get the centroid for each black hole (just grab the first member's embedding)\n",
    "num_holes = len(sorted_holes)\n",
    "D = W.shape[1]\n",
    "black_hole_centroids = torch.zeros(num_holes, D, dtype=W.dtype)\n",
    "\n",
    "for bhid in range(1, num_holes + 1):\n",
    "    # Find first token with this black hole ID\n",
    "    first_token = (black_hole_id == bhid).nonzero()[0].item()\n",
    "    black_hole_centroids[bhid - 1] = W[first_token]\n",
    "\n",
    "print(f\"Black hole centroids shape: {black_hole_centroids.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ../tensors/qwen3_4b_instruct_2507.safetensors\n",
      "File size: 778.3 MB\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(\"../tensors/qwen3_4b_instruct_2507.safetensors\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tensors = {\n",
    "    \"W\": W,\n",
    "    \"black_hole_mask\": black_hole_mask,\n",
    "    \"black_hole_id\": black_hole_id,\n",
    "    \"black_hole_centroids\": black_hole_centroids,\n",
    "}\n",
    "\n",
    "save_file(tensors, output_path)\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(f\"File size: {file_size_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXTRACTION COMPLETE\n",
      "============================================================\n",
      "Model: Qwen/Qwen3-4B-Instruct-2507\n",
      "Vocabulary: 151,936 tokens\n",
      "Embedding dim: 2,560\n",
      "Black holes: 13\n",
      "Tokens in black holes: 2,100\n",
      "Output: ../tensors/qwen3_4b_instruct_2507.safetensors\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXTRACTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: {MODEL_ID}\")\n",
    "print(f\"Vocabulary: {V:,} tokens\")\n",
    "print(f\"Embedding dim: {D:,}\")\n",
    "print(f\"Black holes: {num_holes}\")\n",
    "print(f\"Tokens in black holes: {black_hole_mask.sum().item():,}\")\n",
    "print(f\"Output: {output_path}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

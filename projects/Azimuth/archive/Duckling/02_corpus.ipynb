{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Prepare the Duckling Corpus\n",
    "\n",
    "Download TinyStories from HuggingFace, tokenize with our truncated GPT-2 tokenizer,\n",
    "and save as a flat tensor for fast training.\n",
    "\n",
    "---\n",
    "\n",
    "*Jeffery Harrell & Alpha, December 1, 2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:04:20.526508Z",
     "iopub.status.busy": "2025-12-01T23:04:20.526281Z",
     "iopub.status.idle": "2025-12-01T23:04:20.532361Z",
     "shell.execute_reply": "2025-12-01T23:04:20.531649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: data/tokenizer\n",
      "Output: data/corpus\n",
      "Max stories: 200,000\n",
      "Sequence length: 512\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TOKENIZER_PATH = Path(\"data/tokenizer\")\n",
    "OUTPUT_PATH = Path(\"data/corpus\")\n",
    "\n",
    "# How many stories to use (None = all)\n",
    "# TinyStories has ~2.1M stories, but we don't need all of them\n",
    "# For Chinchilla-optimal ~58M tokens, we need roughly 100-200K stories\n",
    "MAX_STORIES = 200_000  # Should give us plenty of tokens\n",
    "\n",
    "# Sequence length for training\n",
    "SEQ_LEN = 512\n",
    "\n",
    "print(f\"Tokenizer: {TOKENIZER_PATH}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")\n",
    "print(f\"Max stories: {MAX_STORIES:,}\")\n",
    "print(f\"Sequence length: {SEQ_LEN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:04:20.555346Z",
     "iopub.status.busy": "2025-12-01T23:04:20.555212Z",
     "iopub.status.idle": "2025-12-01T23:04:21.501923Z",
     "shell.execute_reply": "2025-12-01T23:04:21.501517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer: 8,000 tokens\n",
      "PAD token: '<|pad|>' (id=7999)\n",
      "EOS token: '<|endoftext|>' (id=7998)\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(TOKENIZER_PATH)\n",
    "print(f\"Loaded tokenizer: {len(tokenizer):,} tokens\")\n",
    "print(f\"PAD token: {repr(tokenizer.pad_token)} (id={tokenizer.pad_token_id})\")\n",
    "print(f\"EOS token: {repr(tokenizer.eos_token)} (id={tokenizer.eos_token_id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download TinyStories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:04:21.503128Z",
     "iopub.status.busy": "2025-12-01T23:04:21.503034Z",
     "iopub.status.idle": "2025-12-01T23:04:24.723436Z",
     "shell.execute_reply": "2025-12-01T23:04:24.722939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TinyStories from HuggingFace...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stories available: 2,119,719\n",
      "Using first 200,000 stories\n",
      "Selected: 200,000 stories\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading TinyStories from HuggingFace...\")\n",
    "dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "\n",
    "print(f\"Total stories available: {len(dataset):,}\")\n",
    "print(f\"Using first {MAX_STORIES:,} stories\")\n",
    "\n",
    "# Take subset\n",
    "dataset = dataset.select(range(min(MAX_STORIES, len(dataset))))\n",
    "print(f\"Selected: {len(dataset):,} stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:04:24.724570Z",
     "iopub.status.busy": "2025-12-01T23:04:24.724452Z",
     "iopub.status.idle": "2025-12-01T23:04:24.727509Z",
     "shell.execute_reply": "2025-12-01T23:04:24.727155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample story:\n",
      "==================================================\n",
      "One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
      "\n",
      "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
      "\n",
      "Together, they shared the needle and sewed the button on Lily's shirt. It was not difficult for them b\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Peek at a sample\n",
    "print(\"Sample story:\")\n",
    "print(\"=\" * 50)\n",
    "print(dataset[0][\"text\"][:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize All Stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:04:24.728520Z",
     "iopub.status.busy": "2025-12-01T23:04:24.728464Z",
     "iopub.status.idle": "2025-12-01T23:05:10.040318Z",
     "shell.execute_reply": "2025-12-01T23:05:10.039917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing stories...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb9d60b86b0407da4e180f7c682b359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total tokens: 51,110,591\n",
      "Tokens per story (avg): 255.6\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Tokenizing stories...\")\n",
    "\n",
    "all_tokens = []\n",
    "oov_count = 0  # Out of vocab (tokens that get mapped to unk)\n",
    "\n",
    "for story in tqdm(dataset):\n",
    "    text = story[\"text\"]\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # Add EOS token after each story\n",
    "    tokens.append(tokenizer.eos_token_id)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "print(f\"\\nTotal tokens: {len(all_tokens):,}\")\n",
    "print(f\"Tokens per story (avg): {len(all_tokens) / len(dataset):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:05:10.041527Z",
     "iopub.status.busy": "2025-12-01T23:05:10.041457Z",
     "iopub.status.idle": "2025-12-01T23:05:10.992555Z",
     "shell.execute_reply": "2025-12-01T23:05:10.992104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID range: [0, 7998]\n",
      "Vocab size: 8000\n",
      "✓ All tokens within vocab range\n"
     ]
    }
   ],
   "source": [
    "# Check token distribution\n",
    "import numpy as np\n",
    "\n",
    "tokens_array = np.array(all_tokens)\n",
    "max_token = tokens_array.max()\n",
    "min_token = tokens_array.min()\n",
    "\n",
    "print(f\"Token ID range: [{min_token}, {max_token}]\")\n",
    "print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "if max_token >= len(tokenizer):\n",
    "    print(f\"WARNING: Max token {max_token} >= vocab size {len(tokenizer)}!\")\n",
    "else:\n",
    "    print(f\"✓ All tokens within vocab range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:05:10.993671Z",
     "iopub.status.busy": "2025-12-01T23:05:10.993597Z",
     "iopub.status.idle": "2025-12-01T23:05:12.490850Z",
     "shell.execute_reply": "2025-12-01T23:05:12.490387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/corpus/tokens.safetensors\n",
      "File size: 408.9 MB\n",
      "Tokens: 51,110,591\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "# Convert to tensor\n",
    "tokens_tensor = torch.tensor(all_tokens, dtype=torch.long)\n",
    "\n",
    "# Save\n",
    "OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "save_file({\"tokens\": tokens_tensor}, OUTPUT_PATH / \"tokens.safetensors\")\n",
    "\n",
    "file_size = (OUTPUT_PATH / \"tokens.safetensors\").stat().st_size\n",
    "print(f\"Saved: {OUTPUT_PATH / 'tokens.safetensors'}\")\n",
    "print(f\"File size: {file_size / 1e6:.1f} MB\")\n",
    "print(f\"Tokens: {len(tokens_tensor):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dead Token Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:05:12.492184Z",
     "iopub.status.busy": "2025-12-01T23:05:12.492114Z",
     "iopub.status.idle": "2025-12-01T23:05:12.500329Z",
     "shell.execute_reply": "2025-12-01T23:05:12.500001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead token mask saved\n",
      "Live tokens: 8,000 (IDs 0-7999)\n",
      "Dead tokens: 2,000 (IDs 8000-9999)\n",
      "Total vocab: 10,000\n"
     ]
    }
   ],
   "source": [
    "# The embedding matrix will have 10,000 rows\n",
    "# Rows 0-7999: live tokens (from tokenizer)\n",
    "# Rows 8000-9999: phantom dead tokens\n",
    "\n",
    "TOTAL_VOCAB = 10_000\n",
    "LIVE_VOCAB = len(tokenizer)  # 8000\n",
    "DEAD_VOCAB = TOTAL_VOCAB - LIVE_VOCAB  # 2000\n",
    "\n",
    "# Create mask: True for dead tokens\n",
    "dead_mask = torch.zeros(TOTAL_VOCAB, dtype=torch.bool)\n",
    "dead_mask[LIVE_VOCAB:] = True\n",
    "\n",
    "# Also save the dead token IDs explicitly\n",
    "dead_token_ids = torch.arange(LIVE_VOCAB, TOTAL_VOCAB, dtype=torch.long)\n",
    "\n",
    "save_file({\n",
    "    \"dead_mask\": dead_mask,\n",
    "    \"dead_token_ids\": dead_token_ids,\n",
    "}, OUTPUT_PATH / \"dead_tokens.safetensors\")\n",
    "\n",
    "print(f\"Dead token mask saved\")\n",
    "print(f\"Live tokens: {LIVE_VOCAB:,} (IDs 0-{LIVE_VOCAB-1})\")\n",
    "print(f\"Dead tokens: {DEAD_VOCAB:,} (IDs {LIVE_VOCAB}-{TOTAL_VOCAB-1})\")\n",
    "print(f\"Total vocab: {TOTAL_VOCAB:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Budget Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:05:12.501433Z",
     "iopub.status.busy": "2025-12-01T23:05:12.501372Z",
     "iopub.status.idle": "2025-12-01T23:05:12.503328Z",
     "shell.execute_reply": "2025-12-01T23:05:12.503005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus tokens: 51,110,591\n",
      "Chinchilla optimal: 58,000,000\n",
      "Coverage: 88.1%\n",
      "\n",
      "⚠ Would need 1.1 epochs to reach Chinchilla-optimal\n"
     ]
    }
   ],
   "source": [
    "# Chinchilla scaling check\n",
    "# Model: ~2.9M params, optimal tokens ≈ 20 × params = 58M\n",
    "\n",
    "total_tokens = len(tokens_tensor)\n",
    "model_params = 2_900_000\n",
    "chinchilla_optimal = 20 * model_params\n",
    "\n",
    "print(f\"Corpus tokens: {total_tokens:,}\")\n",
    "print(f\"Chinchilla optimal: {chinchilla_optimal:,}\")\n",
    "print(f\"Coverage: {total_tokens / chinchilla_optimal * 100:.1f}%\")\n",
    "\n",
    "if total_tokens >= chinchilla_optimal:\n",
    "    print(f\"\\n✓ Corpus is large enough for Chinchilla-optimal training\")\n",
    "else:\n",
    "    epochs_needed = chinchilla_optimal / total_tokens\n",
    "    print(f\"\\n⚠ Would need {epochs_needed:.1f} epochs to reach Chinchilla-optimal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T23:05:12.504244Z",
     "iopub.status.busy": "2025-12-01T23:05:12.504180Z",
     "iopub.status.idle": "2025-12-01T23:05:12.506187Z",
     "shell.execute_reply": "2025-12-01T23:05:12.505816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DUCKLING CORPUS READY\n",
      "==================================================\n",
      "Stories: 200,000\n",
      "Total tokens: 51,110,591\n",
      "Live vocab: 8,000\n",
      "Dead vocab: 2,000\n",
      "Total vocab: 10,000\n",
      "\n",
      "Files:\n",
      "  data/corpus/tokens.safetensors\n",
      "  data/corpus/dead_tokens.safetensors\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"DUCKLING CORPUS READY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Stories: {len(dataset):,}\")\n",
    "print(f\"Total tokens: {len(tokens_tensor):,}\")\n",
    "print(f\"Live vocab: {LIVE_VOCAB:,}\")\n",
    "print(f\"Dead vocab: {DEAD_VOCAB:,}\")\n",
    "print(f\"Total vocab: {TOTAL_VOCAB:,}\")\n",
    "print(f\"\\nFiles:\")\n",
    "print(f\"  {OUTPUT_PATH / 'tokens.safetensors'}\")\n",
    "print(f\"  {OUTPUT_PATH / 'dead_tokens.safetensors'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04ae34f0d98a4cfc803db3b4b2b3c47e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_95f6aeabdb724175adf2d63160ab4428",
       "max": 200000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cc613938c53c4f91b4d46179028df475",
       "tabbable": null,
       "tooltip": null,
       "value": 200000.0
      }
     },
     "07606a23a58f4718b017fc1c8161e848": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3cfafdf979894ceb9662216289863503": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52b98b633a6045efbbd290703bba9cf6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "61eec41581914f0eb6f52eb9fcebdae3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73ad0c8edb4c44e9b4b0280ddf5a1e74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3cfafdf979894ceb9662216289863503",
       "placeholder": "​",
       "style": "IPY_MODEL_61eec41581914f0eb6f52eb9fcebdae3",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "8fb9d60b86b0407da4e180f7c682b359": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_73ad0c8edb4c44e9b4b0280ddf5a1e74",
        "IPY_MODEL_04ae34f0d98a4cfc803db3b4b2b3c47e",
        "IPY_MODEL_c0bc4ae70d3246dbae471fd0384d9ad5"
       ],
       "layout": "IPY_MODEL_ed230a6796414bd6a3282e4acc4e2401",
       "tabbable": null,
       "tooltip": null
      }
     },
     "95f6aeabdb724175adf2d63160ab4428": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0bc4ae70d3246dbae471fd0384d9ad5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_07606a23a58f4718b017fc1c8161e848",
       "placeholder": "​",
       "style": "IPY_MODEL_52b98b633a6045efbbd290703bba9cf6",
       "tabbable": null,
       "tooltip": null,
       "value": " 200000/200000 [00:45&lt;00:00, 4291.12it/s]"
      }
     },
     "cc613938c53c4f91b4d46179028df475": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ed230a6796414bd6a3282e4acc4e2401": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
